<html>

<head></head>

<body>
  <div class="meta">
    <div class="label">
      <span>V</span>
    </div>
  </div>
  <div class="planet-content">
    <h1>------</h1>
    <p>This page is under construction. Please check back later...</p>
    <h2>Papers</h2>
    <table>
      <thead>
        <tr>
          <th>Title</th>
          <th>Summary</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://arxiv.org/pdf/1711.09846.pdf">Population Based Training of Neural Networks</a></td>
          <td>Hyperparameter optimization/meta-learning similar to evolutionary strategies by discarding the least
            performant and copy-perturbing the most performant at each step, with applications in DL, RL, and even GANs.
          </td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1806.06575.pdf">RenderNet: A deep convolutional network for differentiable
              rendering from 3D shapes</a></td>
          <td>Neural network for different types of 3D rendering &amp; shading, capable of single-image reconstruction
            (i.e. few-shot learning). Is it possible to perform pruning to create NN-based performant renderers?</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1904.01326.pdf">HoloGAN: Unsupervised learning of 3D representations from
              natural images</a></td>
          <td>Training 3D representations via backprop on 2D renders. Is it possible to do few-shot learning?</td>
        </tr>
        <tr>
          <td><a href="https://numer.ai/whitepaper.pdf">Numeraire: A Cryptographic Token for Coordinating Machine
              Intelligence and Preventing Overfitting</a></td>
          <td>Betting system for models which incentivizes betters to reveal expected model performance.</td>
        </tr>
        <tr>
          <td><a href="http://www.herrold.com/brokerage/kelly.pdf">A New Interpretation of Information Rate</a></td>
          <td>The famous Kelly criterion for risk management in maximizing log returns in the long run.</td>
        </tr>
        <tr>
          <td><a href="https://www.cs.cornell.edu/home/kleinber/nips15.pdf">An Impossibility Theorem for Clustering</a>
          </td>
          <td>Clustering algorithms cannot simultaneously satisfy three theoretical axioms of behavior. Consider which
            one we want to break. <a href="http://alexhwilliams.info/itsneuronalblog/2015/10/01/clustering2/">See here
              for another summary</a>.</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1907.02893.pdf">Invariant Risk Minimization</a></td>
          <td>A way to enable better generalization to out-of-distribution data when training on a given distribution.
            Fundamental and theoretical.</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1703.03400.pdf">Model-Agnostic Meta-Learning for Fast Adaptation of Deep
              Networks</a></td>
          <td>Task and model-agnostic method to optimize hyperparameters of models via a trainer model which performs
            backprop on average performance of child model over several unseen tasks.</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1708.00088.pdf">Learning Algorithms for Active Learning</a></td>
          <td>Meta-learning the data selection for active learning based on only seeing the unlabeled data, useful for
            situations with high labeling cost.</td>
        </tr>
        <tr>
          <td><a href="http://www.vldb.org/pvldb/vol12/p223-varma.pdf">Snuba: Automating Weak Supervision to Label
              Training Data</a></td>
          <td>Generate noisy labels for selected unlabeled data for further training by training on a smaller set of
            ground truth labels, outperforming heuristics of similar purpose in training the final model.</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1707.07397.pdf">Synthesizing Robust Adversarial Examples</a></td>
          <td>Training 3D representations whose renders are all 2D adversarial examples. Student research group.</td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1610.03670.pdf">Multi-Task Curriculum Transfer Deep Learning of Clothing
              Attributes</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1804.10851.pdf">Imbalanced Deep Learning by Minority Class Incremental
              Rectification</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1712.03162.pdf">Class Rectification Hard Mining for Imbalanced Deep
              Learning</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1905.03813.pdf">When Deep Learning Met Code Search</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1906.11300v1.pdf">Benign Overfitting in Linear Regression</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1907.05740.pdf">Gated-SCNN: Gated Shape CNNs for Semantic Segmentation</a>
          </td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1907.03961.pdf">A Baseline for 3D Multi-Object Tracking</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1905.13002.pdf">Temporal Parallelization of Bayesian Filters and
              Smoothers</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1907.00787.pdf">CNN-based synthesis of realistic high-resolution LiDAR
              data</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1901.06447.pdf">Learning single-image 3D reconstruction by generative
              modeling of shape, pose and shading</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://arxiv.org/pdf/1907.13052.pdf">GENESIS: Generative Scene Inference and Sampling with
              Object-Centric Latent Representations</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="http://people.csail.mit.edu/karger/Papers/mavo.pdf">Mavo: Creating Interactive Data-Driven Web
              Applications by Authoring HTML</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a
              href="https://poseidon01.ssrn.com/delivery.php?ID=604064031098126097067115068069065103018051001046052028106016011094007109078115031069062043121044102001042025088002114099081106024070038021022095065099018007064104037021071009118084014097015068101065078024084109125104109102099087074027081022007090022&amp;EXT=pdf">Calculating
              and Comparing Security Returns is harder than you think: A Comparison betweenLogarithmic and Simple
              Returns</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200512159">Optimal Gambling Systems for
              Favorable Games</a></td>
          <td></td>
        </tr>
        <tr>
          <td><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1586656">Quant Nugget 2: Linear vs.
              Compounded Returns â€“ Common Pitfalls in Portfolio Management</a></td>
          <td></td>
        </tr>
      </tbody>
    </table>
  </div>
</body>

</html>
